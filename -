import cv2 as cv
import numpy as np
import math
import random
import time

# colors
red = (0,0,255)
green = (0,255,0)
blue = (255,0,0)

def rand_color():
    return (random.randint(0,255),random.randint(0,255),random.randint(0,255))

def sort_y(coords):
    return sorted(coords, key = lambda x:x[1])

def perp(a) :
    return [-a[1], a[0]]

# line segment a given by endpoint a and slope da
# line segment b given by endpoint b and slope db
# return
def seg_intersect(a1,a2, b1,b2) :
    da = a2-a1
    db = b2-b1
    dp = a1-b1
    dap = perp(da) # perperdicular vector to da
    denom = np.dot( dap, db)
    num = np.dot( dap, dp )
    return (num / denom.astype(float))*db + b1

# Capture the webcam. Change the number if no work
vid = cv.VideoCapture(2)

calibration = np.array([736.6773965, 0., 340.95853941, 0., 736.16588227, 230.1742966,  0., 0., 1.])
cv.namedWindow('warped', cv.WINDOW_NORMAL)
cv.namedWindow('path', cv.WINDOW_NORMAL)

grid_size = 140
true_pts = np.array([
             [-1,+2],          [+1,+2],
    [-2,+1], [-1,+1], [ 0,+1], [+1,+1], [+2,+1],
             [-1, 0],          [+1, 0],
    [-2,-1], [-1,-1], [ 0,-1], [+1,-1], [+2,-1],
             [-1,-2],          [+1,-2]
])
print(true_pts)

# Image features
matcher = cv.BFMatcher(cv.NORM_L2, crossCheck=True)
old_pts = []

# _position 
old_pos = [500,100]
path = np.zeros((1000,1000,3), np.uint8)

while True:
      
    # Read every frame
    ret, img = vid.read()

    # Mask by hue-saturation-value
    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)
    lower = np.array([10,120,50])
    upper = np.array([25,255,255])
    mask = cv.inRange(hsv, lower, upper)

    # Perspective project to top-down view
    (Y, X) = img.shape[0:2]
    w = 1800
    Yf = int(Y*1.78)
    srcPlane = np.float32([[0, 0], [X, 0], [X+w, Y], [-w, Y]])
    dstPlane = np.float32([[0, 0], [X, 0], [X, Yf], [0, Yf]])
    homographyMat = cv.getPerspectiveTransform(srcPlane, dstPlane)
    warped = cv.warpPerspective(img, homographyMat, (X, Yf))

    # Find contours in mask
    new_pts = []
    contours, hierarchy = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
    for contour in contours:

        # Filter out small contours (likely noise)
        area = cv.contourArea(contour)
        if area < 100: continue

        # Find bounding convex hull
        hull = cv.convexHull(contour)
        #cv.drawContours(img, [hull], -1, blue, 1)

        # Find bounding rotated rectangle
        rect = cv.minAreaRect(hull)
        box = np.int0(cv.boxPoints(rect))
        #cv.drawContours(img, [box], -1, green, 1)

        # Find centroid
        M = cv.moments(contour)
        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))

        # Fit line segment
        [[vx], [vy], [x], [y]] = cv.fitLine(hull, cv.DIST_L2, 0, 0.01, 0.01)
        [left, right] = sort_y(box)[2:]
        bottom = np.int16(seg_intersect(
            np.array([x,y]), 
            np.array([x+vx,y+vy]),
            np.array(left), 
            np.array(right))
        )

        # Perspective project these features
        [wbottom, wleft, wright, wcenter] = np.int16(cv.perspectiveTransform(np.float32([
            [bottom, left, right, center]
        ]), homographyMat)[0])

        new_pts.append(wbottom)

        cv.line(img, bottom, center, blue, 1)
        cv.line(warped, wbottom, wcenter, blue, 1)

        cv.line(img, left, right, blue, 1)
        cv.line(warped, wleft, wright, blue, 1)

    if len(old_pts) and len(new_pts):
        # Find similarities 
        matches = matcher.match(np.float32(old_pts), np.float32(new_pts))
        matches = sorted(matches, key = lambda x:x.distance)

        matchedOld_pts = []
        matchedNew_pts = []

        for match in matches:

            oldPt = old_pts[match.queryIdx]
            newPt = new_pts[match.trainIdx]

            delta = np.subtract(newPt, oldPt)

            matchedOld_pts.append(oldPt)
            matchedNew_pts.append(newPt)

            cv.line(warped, oldPt, newPt, red, 4)
            cv.line(warped, oldPt-3*delta, newPt, red, 2)

        if len(matchedOld_pts) >= 2:
            transformation, inliers = cv.estimateAffinePartial2D(
                    np.array([matchedOld_pts]),
                    np.array([matchedNew_pts])
                )
            new_pos = transformation.dot([old_pos[0], old_pos[1], 1])
            path = (path * 0.99).astype("uint8")
            cv.line(path, np.int16(old_pos), np.int16(new_pos), rand_color(), 2)
            print(new_pos)
            old_pos = new_pos


    if len(new_pts):
        old_pts = new_pts.copy()

    #cv.imshow("img", img)
    cv.rectangle(warped, (236, 715), (236+gridSize, 715-gridSize), red)
    cv.imshow("warped", warped)
    cv.imshow("path", path)


    ##time.sleep(0.5)
      
    # the 'q' button is set as the
    # quitting button you may use any
    # desired button of your choice
    if cv.waitKey(1) & 0xFF == ord('q'):
        break
  
# After the loop release the cap object
vid.release()
# Destroy all the windows
cv.destroyAllWindows()

